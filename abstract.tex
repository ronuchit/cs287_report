\begin{abstract}
In mobile manipulation planning, it is not uncommon for tasks to require thousands of
individual motions. Such problems require
reasoning about courses of action from the viewpoint of logical
objectives as well as the feasibility of individual movements in the
configuration space. In discrete representations, planning complexity
is exponential in the length of the plan; in mobile manipulation, the
set of parameters for an action is often continuous, so we must also
cope with an infinite branching factor. \emph{Task and motion planning} (TAMP)
methods integrate logical search with continuous geometric reasoning
to address this challenge. Our recent work in TAMP has developed a 
\emph{plan refinement graph}, a data structure which holds candidate task plans
that address different infeasibilities. The work included a preliminary technique
for learning to explore this graph. In this paper, we improve this approach,
developing techniques for using statistical machine learning and learning from demonstrations to guide the search process.
Our methods learn from human-demonstrated optimal trajectories through the space of available task plans.
Our contributions are as follows: 1) we formulate navigation through a plan
refinement graph as an MDP; 2) we present a method that trains
heuristics for intelligently searching the available space of task plans, through learning
from expert demonstrations; and 3)
we run experiments to evaluate the performance of our system in a
variety of simulated domains. We show improvements in
performance over the systems we build on.
\end{abstract}
